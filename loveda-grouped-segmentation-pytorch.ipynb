{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7249999,"sourceType":"datasetVersion","datasetId":4200474}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pietrobrugnolo11/loveda-grouped-segmentation-pytorch?scriptVersionId=155873086\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:30.854293Z","iopub.execute_input":"2023-12-20T21:08:30.854701Z","iopub.status.idle":"2023-12-20T21:08:42.643003Z","shell.execute_reply.started":"2023-12-20T21:08:30.854666Z","shell.execute_reply":"2023-12-20T21:08:42.641867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport os\nimport sys\nimport gc\nimport argparse\nimport torch.optim as optim\nimport numpy as np\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms as T\nfrom torch.utils.data import Dataset\nfrom PIL import Image \nfrom torch.utils.data import DataLoader\nfrom torchvision.models.segmentation import deeplabv3_resnet50\nimport segmentation_models_pytorch as smp \n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device, \"\\n\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-20T21:08:42.645011Z","iopub.execute_input":"2023-12-20T21:08:42.645333Z","iopub.status.idle":"2023-12-20T21:08:42.65357Z","shell.execute_reply.started":"2023-12-20T21:08:42.645304Z","shell.execute_reply":"2023-12-20T21:08:42.652648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, data_path, transform=None):\n        self.data_path = data_path\n        self.transform = transform\n        self.image_filenames = []  # List to store image file names\n        self.mask_filenames = []  # List to store mask file names\n\n        # Load image and mask file names\n        self.images_dir = os.path.join(self.data_path, 'images_png')\n        self.masks_dir = os.path.join(self.data_path, 'masks_png')\n        self.image_filenames = sorted(os.listdir(self.images_dir))\n        self.mask_filenames = sorted(os.listdir(self.masks_dir))\n\n    def __len__(self):\n        return len(self.image_filenames)\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.images_dir, self.image_filenames[idx])\n        mask_path = os.path.join(self.masks_dir, self.mask_filenames[idx])\n        # Load image and mask\n        image = Image.open(image_path).convert(\"RGB\")\n        mask = Image.open(mask_path).convert('L')\n        if self.transform is not None:\n            state = torch.get_rng_state()\n            image = self.transform(image)\n            torch.set_rng_state(state)\n            mask = self.transform(mask)\n            \n        imageT = T.ToTensor()\n        maskT = T.PILToTensor()\n\n        #image = np.array(image)\n        #mask = np.array(mask)\n        #image = np.transpose(image, (1, 2, 0)).astype(np.float32)\n        #return (torch.from_numpy(image), torch.from_numpy(mask))\n        return imageT(image), maskT(mask)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.654751Z","iopub.execute_input":"2023-12-20T21:08:42.655016Z","iopub.status.idle":"2023-12-20T21:08:42.668492Z","shell.execute_reply.started":"2023-12-20T21:08:42.654994Z","shell.execute_reply":"2023-12-20T21:08:42.667795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coef(y_pred, y_true, epsilon=1e-7):\n    dice = []\n    \n    # compute for each class \n    classes = int(np.max(np.unique(y_true.detach().cpu().numpy())))\n    for num_class in range(1, classes):\n        target = (y_true == num_class)\n        pred = (y_pred == num_class)\n        \n        intersect = (target * pred).sum()\n        base = (target).sum() + (pred).sum()\n        del(target); del(pred)\n        \n        score = (2 * intersect + epsilon) / (base + epsilon)\n        dice.append(score)\n        del(intersect); del(base)\n    \n    return (sum(dice) / len(dice)).item()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.670614Z","iopub.execute_input":"2023-12-20T21:08:42.670871Z","iopub.status.idle":"2023-12-20T21:08:42.68155Z","shell.execute_reply.started":"2023-12-20T21:08:42.67085Z","shell.execute_reply":"2023-12-20T21:08:42.680714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNET\n\nclass conv_block(nn.Module):\n\n    def __init__(self, ch_in, ch_out, norm_layer=None):\n        super(conv_block, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            #nn.BatchNorm2d(ch_out),\n            norm_layer(num_features=ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            #nn.BatchNorm2d(ch_out),\n            norm_layer(num_features=ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass up_conv(nn.Module):\n    def __init__(self, ch_in, ch_out, norm_layer=None):\n        super(up_conv, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            norm_layer(num_features=ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.up(x)\n        return x\n\n\nclass U_Net(nn.Module):\n    def __init__(self, img_ch=3, output_ch=1, norm_layer=None):\n        super(U_Net, self).__init__()\n\n        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch, ch_out=64, norm_layer=norm_layer)\n        self.Conv2 = conv_block(ch_in=64, ch_out=128, norm_layer=norm_layer)\n        self.Conv3 = conv_block(ch_in=128, ch_out=256, norm_layer=norm_layer)\n        self.Conv4 = conv_block(ch_in=256, ch_out=512, norm_layer=norm_layer)\n        self.Conv5 = conv_block(ch_in=512, ch_out=1024, norm_layer=norm_layer)\n\n        self.Up5 = up_conv(ch_in=1024, ch_out=512, norm_layer=norm_layer)\n        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512, norm_layer=norm_layer)\n\n        self.Up4 = up_conv(ch_in=512, ch_out=256, norm_layer=norm_layer)\n        self.Up_conv4 = conv_block(ch_in=512, ch_out=256, norm_layer=norm_layer)\n\n        self.Up3 = up_conv(ch_in=256, ch_out=128, norm_layer=norm_layer)\n        self.Up_conv3 = conv_block(ch_in=256, ch_out=128, norm_layer=norm_layer)\n\n        self.Up2 = up_conv(ch_in=128, ch_out=64, norm_layer=norm_layer)\n        self.Up_conv2 = conv_block(ch_in=128, ch_out=64, norm_layer=norm_layer)\n\n        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        # encoding path\n        x1 = self.Conv1(x)\n        # print(\"U_Net forward:\", type(x))\n        # print(\"U_Net forward:\", x.shape)\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n\n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)  # self.Conv4 = conv_block(ch_in=256,ch_out=512)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)  # self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n        # print(\"U_Net forward:\", \"encoding\", type(x5))\n        # print(\"U_Net forward:\", \"encoding\", x5.shape)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)  # self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        d5 = torch.cat((x4, d5), dim=1)\n\n        d5 = self.Up_conv5(d5)\n\n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3, d4), dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2, d3), dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1, d2), dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        # print(\"U_Net forward:\", \"dencoding\", type(d1))\n        # print(\"U_Net forward:\", \"dencoding shape\", d1.shape)\n        return d1","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.682906Z","iopub.execute_input":"2023-12-20T21:08:42.683165Z","iopub.status.idle":"2023-12-20T21:08:42.704236Z","shell.execute_reply.started":"2023-12-20T21:08:42.683142Z","shell.execute_reply":"2023-12-20T21:08:42.703399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define parmeters and folders\nclass Opt():\n    def __init__(self):\n        self.learning_rate = 0.001\n        self.print_freq = 75\n        self.name_net = 'unet'  # pspnet, deeplab\n        self.batch_size = 2\n        self.num_workers = 2\n        self.epochs = 4 \n        self.num_classes = 10\n        # Folders\n        self.project_folder = '/kaggle/working/'\n        self.train_data_folder = '/kaggle/input/loveda-grouped/LoveDA_grouped/Train/Train'\n        self.val_data_folder = '/kaggle/input/loveda-grouped/LoveDA_grouped/Val/Val'\n        self.results_folder = os.path.join(self.project_folder, 'results')\n        if not os.path.isdir(self.results_folder):\n            os.makedirs(self.results_folder)\n            \nopt = Opt()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.705318Z","iopub.execute_input":"2023-12-20T21:08:42.705621Z","iopub.status.idle":"2023-12-20T21:08:42.718495Z","shell.execute_reply.started":"2023-12-20T21:08:42.705597Z","shell.execute_reply":"2023-12-20T21:08:42.717741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_model(opt):\n    if opt.name_net == 'unet':\n        model = U_Net(output_ch = opt.num_classes)\n        \n    if opt.name_net == 'pspnet':\n        model = smp.PSPNet('resnet34', in_channels=3, classes = opt.num_classes)\n        \n    if opt.name_net == 'deeplab':\n        model = deeplabv3_resnet50(num_classes = opt.num_classes)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=opt.learning_rate)\n    # scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n\n    if torch.cuda.is_available():\n        model = model.cuda()\n        criterion = criterion.cuda()\n        cudnn.benchmark = True\n\n    return model, criterion, optimizer","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.719552Z","iopub.execute_input":"2023-12-20T21:08:42.719851Z","iopub.status.idle":"2023-12-20T21:08:42.732774Z","shell.execute_reply.started":"2023-12-20T21:08:42.719808Z","shell.execute_reply":"2023-12-20T21:08:42.731901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_model(model, optimizer, opt, epoch, save_file):\n    print('==> Saving...')\n    state = {\n        'opt': opt,\n        'model': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'epoch': epoch,\n    }\n    torch.save(state, save_file)\n    del state","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.733867Z","iopub.execute_input":"2023-12-20T21:08:42.73414Z","iopub.status.idle":"2023-12-20T21:08:42.742538Z","shell.execute_reply.started":"2023-12-20T21:08:42.734118Z","shell.execute_reply":"2023-12-20T21:08:42.741717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_loader(opt):\n\n    # normalize = transforms.Normalize(mean=opt.mean, std=opt.std)\n\n    data_transforms = T.Compose([\n        T.RandomHorizontalFlip(),\n        T.RandomVerticalFlip(),\n        T.RandomRotation(15),\n        T.Resize((128, 256)),\n    ])\n\n    train_dataset = SegmentationDataset(opt.train_data_folder, transform=data_transforms)\n    train_loader = DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n    val_dataset = SegmentationDataset(opt.val_data_folder)\n    val_loader = DataLoader(val_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.num_workers)\n\n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.743646Z","iopub.execute_input":"2023-12-20T21:08:42.744014Z","iopub.status.idle":"2023-12-20T21:08:42.75422Z","shell.execute_reply.started":"2023-12-20T21:08:42.743983Z","shell.execute_reply":"2023-12-20T21:08:42.753515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, test_loader, criterion, opt):\n    model.eval()\n    val_loss = 0\n    val_dice = 0\n    total_num = 0\n    with torch.no_grad():\n        for image, mask in test_loader:\n            if torch.cuda.is_available():\n                image = image.cuda(non_blocking=True)\n                mask = mask.cuda(non_blocking=True)\n                \n            if opt.name_net == 'deeplab':\n                output = model(image)['out'] #with deeplab from torch\n            else:\n                output = model(image)\n                \n            mask = torch.squeeze(mask, dim = 1)\n            loss = criterion(output, mask.long()) # mask.long() if using cross entropy\n            total_num += mask.shape[0]\n            val_loss += loss.item() * mask.shape[0]\n            dice = dice_coef(output.argmax(dim=1), mask)\n            val_dice += dice\n    \n    val_loss = val_loss / total_num      \n    val_dice = val_dice / len(test_loader)\n    print(\"validation loss\", val_loss)\n    print(\"validation DICE coefficient\", val_dice) \n    \n    return val_loss, val_dice","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.757366Z","iopub.execute_input":"2023-12-20T21:08:42.757768Z","iopub.status.idle":"2023-12-20T21:08:42.767133Z","shell.execute_reply.started":"2023-12-20T21:08:42.757743Z","shell.execute_reply":"2023-12-20T21:08:42.766246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, test_loader, criterion, optimizer, epoch, opt):\n    model.train()\n    total_loss, total_num = 0.0, 0\n    idx = 0\n    # for image, mask in train_loader:\n    for image, mask in train_loader:\n        optimizer.zero_grad()\n        # print(torch.unique(mask)) # Must be integers\n        if torch.cuda.is_available():\n            image = image.cuda(non_blocking=True)\n            mask = mask.cuda(non_blocking=True)\n\n        # forward + backward + optimize\n        if opt.name_net == 'deeplab':\n            output = model(image)['out'] #with deeplab from torch\n        else:\n            output = model(image)\n        \n        mask = torch.squeeze(mask, dim = 1)\n        # print('mask shape', mask.shape)\n        # print('output shape', output.shape)\n        loss = criterion(output, mask.long()) # mask.long() if using cross entropy\n        loss.backward()\n        optimizer.step()\n\n        total_num += mask.shape[0]\n        total_loss += loss.item() * mask.shape[0]\n\n        if (idx + 1) % opt.print_freq == 0:\n            print('Train Epoch: [{}/{}], lr: {:.6f}, Loss: {}'.format(epoch, opt.epochs,\n                                                                    optimizer.param_groups[0]['lr'],\n                                                                    total_loss / total_num))\n\n            sys.stdout.flush()\n        idx += 1\n\n        gc.collect()\n        torch.cuda.empty_cache()\n    val_loss, val_dice = test(model, test_loader, criterion, opt)\n    print(\"train() function - epoch total_loss\", total_loss / total_num)\n    train_loss = total_loss / total_num\n    return train_loss, val_loss, val_dice ","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.768211Z","iopub.execute_input":"2023-12-20T21:08:42.7685Z","iopub.status.idle":"2023-12-20T21:08:42.778454Z","shell.execute_reply.started":"2023-12-20T21:08:42.768469Z","shell.execute_reply":"2023-12-20T21:08:42.777592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\n# build data loader\ntrain_loader, test_loader = set_loader(opt)\nprint('train e test data loader created...')\n\n# define model\nmodel, criterion, optimizer = set_model(opt)\nsave_file_1 = os.path.join(opt.results_folder, (str(opt.name_net) + '_best.pth'))\n\n# TRAINING\nprint(\"Training...\")\n\n# training routine\nbest_val_dice = 0\ntrain_loss_values, val_loss_values, val_dices = [], [], []\n\nfor epoch in range(1, opt.epochs + 1):\n\n    train_loss, val_loss, val_dice = train(model, train_loader, test_loader, criterion, optimizer, epoch, opt)\n    train_loss_values.append(train_loss)\n    val_loss_values.append(val_loss)\n    val_dices.append(val_dice)\n\n    # save best model\n    if val_dice > best_val_dice:\n        print(\"saving/updating current best model at epoch=\" + str(epoch))\n        save_model(model, optimizer, opt, epoch, save_file_1)\n        best_val_dice = val_dice\n\n    # save loss values and plot\n    tloss_df = pd.DataFrame(train_loss_values)\n    vloss_df = pd.DataFrame(val_loss_values)\n    dice_df = pd.DataFrame(val_dices)\n    tloss_df.to_csv(opt.results_folder +'/' + (str(opt.name_net) + '_train_loss.csv'))\n    vloss_df.to_csv(opt.results_folder +'/' + (str(opt.name_net) + '_val_loss.csv'))\n    dice_df.to_csv(opt.results_folder +'/' + (str(opt.name_net) + '_val_dice.csv'))\n\n    plt.figure(figsize=(15, 10))\n    plt.plot(train_loss_values, label = 'train loss')\n    plt.ylabel('train loss value')\n    plt.xlabel('epochs')\n    plt.savefig(opt.results_folder +'/' + str(opt.name_net) + ' _train_loss.png')\n    plt.close()\n\n    plt.figure(figsize=(15, 10))\n    plt.plot(val_loss_values, label = 'validation loss')\n    plt.ylabel('validation loss value')\n    plt.xlabel('epochs')\n    plt.savefig(opt.results_folder +'/' + str(opt.name_net) + ' _val_loss.png')\n    plt.close()\n\n    plt.figure(figsize=(15, 10))\n    plt.plot(val_dices)\n    plt.ylabel('dice value')\n    plt.xlabel('epochs')\n    plt.savefig(opt.results_folder +'/' + str(opt.name_net) + ' _val_dice.png')\n    plt.close()\n\n\n# save the last model\nsave_file_2 = os.path.join(opt.results_folder, (str(opt.name_net) + '_last.pth'))\nsave_model(model, optimizer, opt, opt.epochs, save_file_2)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:08:42.779658Z","iopub.execute_input":"2023-12-20T21:08:42.779932Z","iopub.status.idle":"2023-12-20T22:04:54.883984Z","shell.execute_reply.started":"2023-12-20T21:08:42.77991Z","shell.execute_reply":"2023-12-20T22:04:54.882964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot results\n\nmodel.eval()\n\nim_transforms = T.Compose([\n    T.Resize((128, 256)),\n    T.ToTensor(),\n])\n\nmask_transforms = T.Compose([\n    T.Resize((128, 256)),\n])\n\nim1 = Image.open('/kaggle/input/loveda-grouped/LoveDA_grouped/Val/Val/images_png/2540.png')\nim2 = Image.open('/kaggle/input/loveda-grouped/LoveDA_grouped/Val/Val/images_png/4132.png')\nim3 = Image.open('/kaggle/input/loveda-grouped/LoveDA_grouped/Val/Val/images_png/4066.png')\n\nmask1 = Image.open('/kaggle/input/loveda-grouped/LoveDA_grouped/Val/Val/masks_png/2540.png')\nmask2 = Image.open('/kaggle/input/loveda-grouped/LoveDA_grouped/Val/Val/masks_png/4132.png')\nmask3 = Image.open('/kaggle/input/loveda-grouped/LoveDA_grouped/Val/Val/masks_png/4066.png')\n\nim1 = im_transforms(im1)\nim2 = im_transforms(im2)\nim3 = im_transforms(im3)\n\nmask1 = mask_transforms(mask1)\nmask2 = mask_transforms(mask2)\nmask3 = mask_transforms(mask3)\n\nif torch.cuda.is_available():\n    im1 = im1.cuda(non_blocking=True)\n    #mask1 = mask1.cuda(non_blocking=True)\n    im2 = im2.cuda(non_blocking=True)\n    #mask2 = mask2.cuda(non_blocking=True)\n    im3 = im3.cuda(non_blocking=True)\n    #mask3 = mask3.cuda(non_blocking=True)\n    \nif opt.name_net == 'deeplab': \n    pred1 = model(im1[None,:,:,:])['out']\n    pred2 = model(im2[None,:,:,:])['out']\n    pred3 = model(im3[None,:,:,:])['out']\nelse:\n    pred1 = model(im1[None,:,:,:])\n    pred2 = model(im2[None,:,:,:])\n    pred3 = model(im3[None,:,:,:])\n    \npred1 = torch.squeeze(pred1)\npred1 = pred1.argmax(0).squeeze()\npred1 = pred1.cpu().detach().numpy()\npred2 = torch.squeeze(pred2)\npred2 = pred2.argmax(0).squeeze()\npred2 = pred2.cpu().detach().numpy()\npred3 = torch.squeeze(pred3)\npred3 = pred3.argmax(0).squeeze()\npred3 = pred3.cpu().detach().numpy()\n\nfig , ax =  plt.subplots(3, 3, figsize=(18, 18))\nax[0][0].set_title('Image')\nax[0][1].set_title('Label')\nax[0][2].set_title('Prediction')\nax[1][0].set_title('Image')\nax[1][1].set_title('Label')\nax[1][2].set_title('Prediction')\nax[2][0].set_title('Image')\nax[2][1].set_title('Label')\nax[2][2].set_title('Prediction')\nax[0][0].imshow(np.squeeze(np.transpose(im1.squeeze().cpu(),(1,2,0))))\nax[0][1].imshow(mask1)\nax[0][2].imshow(pred1.squeeze(), vmin = 0, vmax = 9)\nax[1][0].imshow(np.squeeze(np.transpose(im2.squeeze().cpu(),(1,2,0))))\nax[1][1].imshow(mask2)\nax[1][2].imshow(pred2.squeeze())\nax[2][0].imshow(np.squeeze(np.transpose(im3.squeeze().cpu(),(1,2,0))))\nax[2][1].imshow(mask3)\nax[2][2].imshow(pred3.squeeze())\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:04:54.885567Z","iopub.execute_input":"2023-12-20T22:04:54.885922Z","iopub.status.idle":"2023-12-20T22:04:57.27307Z","shell.execute_reply.started":"2023-12-20T22:04:54.885892Z","shell.execute_reply":"2023-12-20T22:04:57.27219Z"},"trusted":true},"execution_count":null,"outputs":[]}]}